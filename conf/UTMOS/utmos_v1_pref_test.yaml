model: 
    modules:
        modules_0:
            model_class: model.features.wav2vec:featureExtractor
            save: True
            freeze: False
            inputs: ['_dataset_feat_x0']
            arch:
                conf:
                    cp_path: pretrained_models/wav2vec_small.pt
                    device: cuda
            output: ['wav2vec']

        modules_1:
            model_class: model.UTMOS.model:Model
            save: True
            freeze: False
            inputs: ['wav2vec', '_dataset_feat_x1', '_dataset_feat_x2', '_dataset_feat_x3', '_dataset_feat_x4', '_ids', '_dataset_feat_x5']
            arch: 
                conf: 
                    hidden_dim: 256
                    emb_dim: 256
                    out_dim: 256
                    n_lstm_layers: 3
                    vocab_size: 2048
                    n_domains: 5
                    domain_dim: 128

                    judge_dim: 128
                    num_judges: 3500
                    projection_hidden_dim: 2048
                    range_clipping: False
                    pref_mode: pref

            output: ['frame_class_score', 'gt_pref_score', 'utt_pref_score', 'utt_class_score', '_ids']

dataset:
    features: ['wav#wav.scp', 'text.listchar', 'ref.listchar', 'domain.emb', 'judge_id.emb', 'score_norm.txt']
    label: []
    fs: 16000
    
    collate_fns: 
        _default: 'repetitive_to_max'
        text.listchar: 'pad_to_max'
        ref.listchar: 'pad_to_max'

    batch_size:
        _default: 3
        dev: 1
        test: 1

    data_augmentation:
        wav#wav.scp:
            -
                augment: model.augment.AugmentWav:AugmentWav
                conf:
                    pitch_shift_minmax:
                        min: -300
                        max: 300
                    random_time_warp_f: 1.0
                aug_when_inferring: False
            -
                augment: model.augment.SliceWav:SliceWav
                conf:
                    max_wav_seconds: 10
                aug_when_inferring: False


# multiple_optimizer
optimizer:
    type: torch.optim:Adam
    conf:
        lr: 0.00002

scheduler:
    type: transformers:get_linear_schedule_with_warmup
    conf: 
        num_warmup_steps: 4000
        num_training_steps: 15000

trainer:
    iteration_type: 'iteration'
    iterations: 60000
    save_per_iterations: 5000
    eval_per_iterations: 5000
    accum_grad: 4
    loss:
        ClippedMSELoss:
            criterion_class: model.nn.losses:batchedCELoss
            inputs: ['utt_class_score', 'gt_pref_score']
            weight: 1

logger:
    log_metrics: False
    logger_conf: conf/UTMOS/logger_score_pref.yaml
    save: ['pred_utt_score.txt#utt_pref_score', 'gt_score.txt#gt_pref_score']
